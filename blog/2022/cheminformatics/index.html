<!DOCTYPE html> <html lang="en"> <head> <meta name="google-site-verification" content="google-site-verification=google5d0dde76b59b2bd0.html"/> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Fundamentals of CYP3A4 Binding | Amitesh Badkul</title> <meta name="author" content="Amitesh Badkul"/> <meta name="description" content="CYP3A4 inhibition prediction"/> <meta name="keywords" content="deep learning, bioinformatics, machine learning, image processing"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üí≠</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://amiteshbadkul.github.io/blog/2022/cheminformatics/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://amiteshbadkul.github.io/"><span class="font-weight-bold">Amitesh¬†</span>Badkul</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Fundamentals of CYP3A4 Binding</h1> <p class="post-meta">March 25, 2022</p> <p class="post-tags"> <a href="https://amiteshbadkul.github.io/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> ¬† ¬∑ ¬† <a href="//blog/tag/cheminformatics"> <i class="fas fa-hashtag fa-sm"></i> cheminformatics</a> ¬† <a href="//blog/tag/ml"> <i class="fas fa-hashtag fa-sm"></i> ml</a> ¬† <a href="//blog/tag/dl"> <i class="fas fa-hashtag fa-sm"></i> dl</a> ¬† ¬† ¬∑ ¬† <a href="https://amiteshbadkul.github.io/blog/category/cheminformatics"> <i class="fas fa-tag fa-sm"></i> cheminformatics</a> ¬† </p> </header> <article class="post-content"> <h2 id="introduction">Introduction</h2> <p>To understand the general flow of QSAR predictive modeling, I selected the problem of binary classification of the cytochrome P450 3A4 inhibition. In principle, binary classification is more straightforward to model and understand. Moreover, it is easier to identify the fallacies involved in creating the models and curating the datasets involved.</p> <p>CYP3A4 is an important enzyme in the body, mainly found in the liver and in the intestine. It oxidizes small foreign organic molecules, such as toxins or drugs, so that they can be removed from the body.</p> <p>The modeling done can be replicated for the other CYP450 enzymes as well.</p> <h2 id="dataset">Dataset</h2> <p>The dataset used for binary classification was created by Veith et al. to better predict the interaction of a large variety of drugs with the CYP450 enzymes.</p> <p>The dataset contains drugs from:</p> <ol> <li> <a href="https://pubchem.ncbi.nlm.nih.gov/source/MLSMR" target="_blank" rel="noopener noreferrer">MLSMR</a> - contains chemically diverse small compounds based on Lipinski‚Äôs rule of five, synthetic tractability, and availability.</li> <li>6,144 compounds from a set of bio focused libraries, which included 1,114 FDA-approved drugs</li> <li>980 compounds from combinatorial libraries containing privileged structures targeted at GPCRs and kinases and libraries of purified natural products or related structure</li> </ol> <p>Understanding the selection criterion -</p> <ol> <li> <strong>Lipinski‚Äôs rule of five</strong>: Lipinski‚Äôs rule of 5 helps distinguish between drug-like and non-drug-like molecules. Suppose the compound in question complies with at least two of the following rules. In that case, it is associated with a high probability of drug-likeness - Molecular mass less than 500 Dalton, high lipophilicity (expressed as LogP less than 5), less than five hydrogen bond donors, less than ten hydrogen bond acceptors, and molar refractivity should be between 40-130. If a drug satisfies all the constraints mentioned, it is highly likely to have good permeation and absorption. A drug‚Äôs permeability across biological membranes is a critical factor influencing absorption and distribution. If a drug wants to reach systemic circulation, it needs to cross several semipermeable cell membranes first. Hence, Lipinski‚Äôs rule of five is an important criterion.</li> <li> <strong>Synthetic tractability</strong>: Medicinal chemists evaluate compounds according to their synthesis feasibility and other parameters such as up-scaling or cost of goods.</li> <li> <strong>Focused Libraries</strong>: A target-focused library is a collection of compounds that have been either designed or assembled with a protein target or protein family in mind.</li> <li> <strong>Combinatorial libraries</strong>: These are collections of chemical compounds, small molecules, or macromolecules such as proteins, synthesized by combinatorial chemistry, in which multiple different combinations of related chemical species are reacted together in similar chemical reactions.</li> </ol> <h3 id="dataset-curation">Dataset Curation</h3> <p>The dataset is downloaded from <a href="https://tdcommons.ai/single_pred_tasks/adme/#cyp-p450-3a4-inhibition-veith-et-al" target="_blank" rel="noopener noreferrer">TDCommons</a>. The TDCommons python library has the option of performing various types of splits including random, scaffold, cold-start, and combination split. We utilize the random and scaffold splits.</p> <h2 id="representation-of-the-compounds">Representation of the Compounds</h2> <p>Representation of molecules in the form of vectors is an active research field. A fingerprint is a type of molecular representation that is useful. It is essential to have a method that appropriately represents the molecule so that the machine learning models can accurately perform. Fingerprints exist in various shapes and sizes, and they‚Äôve been used to solve a wide range of problems during the previous few decades. ECFPs (or ‚ÄúCircular Fingerprints‚Äù) provides various advantages over other methods.</p> <p>The advantages of using ECFP include:</p> <ol> <li>The ECFP method comprises fewer units, making it simple to implement.</li> <li>Multiple variations are possible on the base algorithm.</li> <li>The ECFP algorithm is computationally quick.</li> <li>Topological structural information is adequately represented.</li> </ol> <p>The Extended-connectivity fingerprint (ECFP) of bond diameter 4 for the drug compounds was obtained and converted into 1024 bit vector.</p> <p>To understand how exactly the algorithm for the ECFP fingerprint works consider reading the following:</p> <ol> <li><a href="https://chemicbook.com/2021/03/25/a-beginners-guide-for-understanding-extended-connectivity-fingerprints.html" target="_blank" rel="noopener noreferrer">ChemicBook Blog‚Äôs Simple Explanation</a></li> <li><a href="https://pubs.acs.org/doi/10.1021/ci100050t" target="_blank" rel="noopener noreferrer">Rogers and Hahn</a></li> </ol> <h2 id="chemical-space-exploration-and-analysis">Chemical Space Exploration and Analysis</h2> <p>The dataset‚Äôs chemical space was explored to understand better the various molecules present in the dataset as similar molecules are clustered together. In contrast, dissimilar ones are far from each other. We can also understand the similarity between the training, testing, and validation datasets. Principal component analysis or PCA is a commonly employed method to understand the chemical space. PCA is a dimensionality reduction technique that produces new variables using a linear combination of old variables that are better able to describe the dataset. We use the explained variance ratio metric to verify if PCA adequately retained the original variables‚Äô information. The higher the ratio, the more variance from the data is retained. To visualize the chemical space, we reduce the variables to two using PCA.</p> <p align="center" width="100%"> <img width="75%" src="https://i.imgur.com/3OHCq27.png"><br> <i> PC1 and PC2 are the linear combinations of the previous variables </i> </p> <p>PCA is a linear dimension reduction technique that cannot adequately explain the clustering of drugs. In contrast, T-distributed Stochastic Neighbor Embedding (t-SNE) is a non-linear dimensionality reduction technique that can explain the same. The math behind t-SNE is quite complex, but the idea is simple. It embeds the points from a higher dimension to a lower dimension trying to preserve the neighborhood of that point. t-SNE is better able to capture the extent of distribution of the compounds of the dataset.</p> <p align="center" width="100%"> <img width="75%" src="https://i.imgur.com/keANY5J.png"><br> <i> The t-SNE plot is generated such that 95% of the variance is retained </i> </p> <p>To better understand PCA and t-SNE consider reading the following:</p> <ol> <li><a href="https://medium.com/swlh/t-sne-explained-math-and-intuition-94599ab164cf" target="_blank" rel="noopener noreferrer">Achinoam Soroker‚Äôs Simple Explanation</a></li> <li><a href="https://towardsdatascience.com/an-introduction-to-t-sne-with-python-example-5a3a293108d1" target="_blank" rel="noopener noreferrer">Andre Violante‚Äôs Explanation with python example</a></li> <li><a href="https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="noopener noreferrer">Maaten and Hinton</a></li> </ol> <h2 id="cleaning-the-dataset">Cleaning the Dataset</h2> <p>Removal of drug compounds from the dataset, as these drug compounds lead to model instability, with:</p> <ol> <li>Invalid SMILES string.</li> <li>Outlier removal using molecular weight as a descriptor - if the molecule has a weight three times the standard deviations from the mean, it was flagged as an outlier.</li> </ol> <p align="center" width="100%"> <img width="75%" src="https://i.imgur.com/4kTGoKo.png"><br> <i> Histogram distribution after outlier removal </i> </p> <h2 id="classification-models">Classification Models</h2> <p>The following classification algorithms were deployed:</p> <ol> <li>Logistic Regression</li> <li>Random Forests Classifier</li> <li>XGBoost Classifier</li> </ol> <h3 id="evaluation-metrics">Evaluation Metrics</h3> <ol> <li>AUC - ROC (Area Under the Receiver Operating Characteristics) - It helps in quality comparison of various models, the higher the values, the better the model is with respect to distinguishing properly between the two classes.</li> <li>Matthews correlation coefficient (MCC) - is a balanced metric, which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset. It is very suitable for binary classification. MCC provides a measure of the correlation between predictions and observations. A value of 1 represents a perfect agreement, whereas values of 0 and ‚Äì1 correspond to random and perfect disagreement, respectively.</li> </ol> <h3 id="logistic-regression">Logistic Regression</h3> <p>For classification tasks, the logistic regression method is employed. It‚Äôs a probabilistic prediction analysis algorithm. The logistic regression classifier is intended to provide us with a set of outputs or classifications depending on likelihood. We run the data through a prediction algorithm and get a likelihood score between 0 and 1.</p> <p align="center" width="100%"> <img width="75%" src="https://i.imgur.com/N7Z0HVF.png"><br> <i> AUC - ROC of Logistic Regression of training, testing and validation </i> </p> <p>Logistic Regression is a linear classifier, the decision boundary it generates is linear. Since the dependence between molecular descriptors and end points in non-linear, logistic regression overfits on the training data and is unable to predict with similar accuracy on the test and validation set.</p> <p align="center" width="100%"> <img width="75%" src="https://i.imgur.com/0yav04k.png"><br> <i> MCC of the random and scaffold split for training, testing and validation </i> </p> <p>In case of both the random and scaffold split similar results are obtained - possibly due to the random and scaffold split having similar test and validation drug compounds.</p> <h3 id="random-forest-classifier">Random Forest Classifier</h3> <p>Tin Kam Ho introduced the general concept of Random Forests in the year 1995. It is an ensemble classification technique that has high accuracy. The error for classification decreases as the number of trees in the forest increases. Leo Breiman further established random forests more concretely in 2001, he defined random forests as a classifier that consists of a set of tree-based classifiers where each classifier has independent weights and independently casts votes for the most popular class of the data provided.</p> <p>Advantages of Random Forests include:</p> <ol> <li>Reduces overfitting to a large extent.</li> <li>Works on both classification as well as regression problems.</li> <li>Normalization of data is unessential because of the rule-based approach.</li> <li>Has better accuracy as compared to decision trees</li> </ol> <p>Disadvantages of Random Forests include:</p> <ol> <li>The process of training is computational expensive due to the large number of decision trees present.</li> <li>Time required for training is more when compared to decision trees.</li> </ol> <p align="center" width="100%"> <img width="75%" src="https://www.freecodecamp.org/news/content/images/2020/08/how-random-forest-classifier-work.PNG"><br> <i> Random Forest Classifier </i> </p> <p align="center" width="100%"> <img width="75%" src="https://i.imgur.com/p5OrTMH.png"><br> <i> ROC of Random Forest Classifier of training, testing and validation </i> </p> <p>To overcome the issue of linear boundary generation for non-linear data, we use the Random Forest Classifier, a non-linear classifier. In this case, we also see that the model overfits the data, possibly due to producing exact non-linear boundaries for classification. Tuning of Hyperparameters in the RF classifier affects all the decision trees, so one needs to find the tradeoff between the value of the ROC AUC metric obtained and the changes in the hyperparameters.</p> <p align="center" width="100%"> <img width="75%" src="https://i.imgur.com/ZcRsmT0.png"><br> <i> MCC of the random and scaffold split for training, testing and validation </i> </p> <p>The scaffold split train dataset has a higher MCC due to overfitting, whereas the random split model generalizes better. The scaffold split doesn‚Äôt generalize well on unseen data as the test and the validation set contains drugs with scaffolds different from the training set.</p> <h3 id="xgboost-classifier">XGBoost Classifier</h3> <p>Chen and Guestrin from the University of Washington introduced XGBoost in the year 2016. XGBoost is an ensemble learning technique based on decision trees. While there do exist gradient boosting algorithms, none of them are as widely used as XGBoost due to it‚Äôs scalability, and it‚Äôs execution time, it is computationally very quick. XGBoost is known to achieve high accuracy on tabular data. It has the same advantages as random forest with the added advantage that it is quicker. XGBoost optimizes the algorithm to produce such low computational speed and high accuracy.</p> <p>Some features of XGBoost include:</p> <ol> <li>Gradient-based Tree Boosting with L1/L2 Regularization.</li> <li>Construction of parallization on CPU cores.</li> <li>Distributed training on a cluster of machines for a large dataset.</li> <li>Out-of-Core computation for large datasets that cause storage problems.</li> </ol> <p align="center" width="100%"> <img width="75%" src="https://i.imgur.com/yraKhUa.png"><br> <i> AUC - ROC of XGBoost Classifier of training, testing and validation </i> </p> <p>The XGBoost model can overcome the problem of overfitting to a certain extent, as evident by the ROC AUC values of the training, testing, and validation datasets. Even the MCC metric values indicate that there is not much difference between the training, testing, and validation results obtained.</p> <p align="center" width="100%"> <img width="75%" src="https://i.imgur.com/k90hUCS.png"><br> <i> MCC of the random and scaffold split for training, testing and validation </i> </p> <h2 id="discussion">Discussion</h2> <p>Some potential reasons for values of these metrics being moderate and not higher include -</p> <ol> <li>1024 number of bits for the representation of drug molecules don‚Äôt fully capture the structure of molecules.</li> <li>The ECFP radii as 2 are not able to properly represent the molecule.</li> <li>Maybe the ECFP doesn‚Äôt adequately represent the molecules and a different molecular descriptor like Avalon Fingerprints, 2D Pharmacophore Fingerprints, etc.</li> </ol> <h2 id="future-work">Future Work</h2> <p>Future work includes:</p> <ol> <li>Further Evaluation of the results utilizing chemical space analysis on the predicted values and comparing the same to actual results to understand which particular molecule affects the model.</li> <li>Implementation of Deep Learning-based techniques such as Graph Convolutional Neural Networks and Multilayer Perceptron (MLP).</li> <li>Implementation of different descriptors for the drugs.</li> </ol> <h2 id="code">Code</h2> <p>The code for the project is available <a href="https://github.com/AmiteshBadkul/CYP3A4" target="_blank" rel="noopener noreferrer">here</a>.</p> <h2 id="references">References</h2> <ol> <li><a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/minf.201000061" target="_blank" rel="noopener noreferrer">Tropsha, Alexander. ‚ÄúBest practices for QSAR model development, validation, and exploitation.‚Äù Molecular informatics 29.6‚Äê7 (2010): 476-488</a></li> <li><a href="https://www.mdpi.com/1420-3049/26/15/4678" target="_blank" rel="noopener noreferrer">Holmer, Malte, et al. ‚ÄúCYPstrate: A Set of Machine Learning Models for the Accurate Classification of Cytochrome P450 Enzyme Substrates and Non-Substrates.‚Äù Molecules 26.15 (2021): 4678</a></li> <li><a href="https://www.sciencedirect.com/science/article/pii/S1359644620302609" target="_blank" rel="noopener noreferrer">G√∂ller, Andreas H., et al. ‚ÄúBayer‚Äôs in silico ADMET platform: A journey of machine learning over the past two decades.‚Äù Drug Discovery Today 25.9 (2020): 1702-1709</a></li> <li><a href="https://tdcommons.ai/single_pred_tasks/adme/#cyp-p450-3a4-inhibition-veith-et-al" target="_blank" rel="noopener noreferrer">Dataset</a></li> <li><a href="https://ieeexplore.ieee.org/document/598994" target="_blank" rel="noopener noreferrer">Ho, Tin Kam. ‚ÄúRandom decision forests.‚Äù Proceedings of 3rd international conference on document analysis and recognition. Vol. 1. IEEE, 1995</a></li> <li><a href="https://dl.acm.org/doi/abs/10.1145/2939672.2939785" target="_blank" rel="noopener noreferrer">Chen, Tianqi, and Carlos Guestrin. ‚ÄúXgboost: A scalable tree boosting system.‚Äù Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. 2016</a></li> </ol> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Amitesh Badkul. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>